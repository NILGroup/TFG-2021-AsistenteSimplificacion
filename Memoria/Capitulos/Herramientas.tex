\chapter{Herramientas}
\label{cap:herramientas}

	\chapterquote{Siempre llega una nueva herramienta. La tecnología es neutral, depende de cómo se use}{Rick Smolan}

En este capítulo hablaremos sobre las distintas tecnologías utilizadas para el desarrollo del trabajo. Expondremos los motivos por los cuales hemos decidimos usar unas tecnologías frente a otras y hablaremos sobre los
orígenes de las mismas.


\section{Flask}\label{sec:flask}
Dado que decidimos hacer la aplicacion en Python, usamos Flask por que es mas ligero que otros como Django.

Flask es un framework minimalista escrito en Python que permite crear aplicaciones web rápidamente y con un mínimo número de líneas de código. Está basado en la especificación WSGI de Werkzeug y el motor de templates Jinja2 y tiene una licencia BSD.

\section{Spacy}\label{sec:spacy}
Hemos decidido usar Spacy por su facilidad de uso y comodidad a la hora de las transformaciones sintácticas y morfológicas de las palabras.

Spacy es una libreria de codigo abierto gratuita para el procesamiento avanzado del lenguaje natural (Natural Languaje Processing) en Python.

Puede ser usada para extraer informacion, para sistemas de la comprension del lenguaje natural o para el pre-procesado de texto para deep learning.

Las carateristicas y capacidades de Spacy son las siguientes:

\begin{itemize}
	\item \textbf{Tokenization}: segmentación del texto en palabras, signos de puntuacion, etc.
	\item \textbf{Part-of-speech (POS) Tagging}: asigna a los tokens tipos de palabra, como verbo o nombre.
	\item \textbf{Dependency Parsing}: asigna etiquetas de dependencia sintáctica, describiendo la relación entre tokens individuales, como objeto o sujeto.
	\item \textbf{Lemmatization}: asigna la base de las palabras. Por ejemplo, el lema de ``era'' es ``es'' y el de ``ratas'' es ``rata''.
	\item \textbf{Sentence Boundary Detection}: búsqueda y segmentación de frases individuales.
	\item \textbf{Named Entity Recognition}: etiquetado de objetos con nombre del "mundo real", como personas, compañías o lugares.
	\item \textbf{Entity Linking}: desambiguado de entidades textuales a identificadores únicos en una base del conocimiento.
	\item \textbf{Similarity}: comparacion de palabras, intervalos de texto y documentos para saber cuanta similitud tienen entre ellos.
	\item \textbf{Text Classification}: asignación de categorías o etiquetas a un documento completo, o a partes de un documento.
	\item \textbf{Rule-based Matching}: búsqueda de secuencias de tokens basada en sus textos y anotaciones lingüísticas, similar a expresiones regulares.
	\item \textbf{Training}: actualización y mejora de las predicciones del modelo estadístico.
	\item \textbf{Serializatio}: guardado de objetos a ficheros o cadenas de byte.
\end{itemize}
De todas estas características nosotros usaremos principalmente las cinco primeras.

\section{Postman}\label{sec:postman}
Postman es una herramienta que se utiliza, sobre todo, para el testing de API REST, aunque también admite otras funcionalidades que se salen de lo que engloba el testing de este tipo de sistemas.

Gracias a esta herramienta, además de testear, consumir y depurar API REST, podremos monitorizarlas, escribir pruebas automatizadas para ellas, documentarlas, mockearlas, simularlas, etc.

\section{NILWS}\label{sec:nilws}
NILWS es una API del grupo NIL preparada por el proyecto IDiLyCo.
Contiene una gran cantidad de endpoints, de los cuales usaremos los siguientes:
\begin{itemize}
	\item \textbf(es\_sencilla) "/palabra/{palabra}/es\_sencilla" 
	Lo usaremos para saber si una palabra, sin caracteres especiales, es sencilla o no
	\item \textbf(definiciones) "/palabra/{palabra}/definiciones"
	Lo usaremos para mostrar las definiciones de una palabra, sin caracteres especiales.
	\item \textbf(sinonimos) "/palabra/{palabra}/sinonimos" 
	Lo usaremos para obtener los sinonimos de una palabra, sin caracteres especiales.
\end{itemize}